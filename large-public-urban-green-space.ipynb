{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac12c9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fa53b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ee\n",
    "import geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847e3900",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate(auth_mode='notebook')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ad7c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize(project='YOUR-GOOGLE-CLOUD-PROJECT-NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454edfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE CITY AND DATE RANGE FOR ANALYSIS\n",
    "\n",
    "# Prompt the user to enter the city\n",
    "city_name = input(\"Enter your city name: \")\n",
    "\n",
    "# Convert the city name to a valid variable name by removing spaces and hyphens\n",
    "city_var = city_name.replace(\" \", \"\")\n",
    "city_var = city_var.replace(\"-\", \"\")\n",
    "\n",
    "# Define a dictionary to store FeatureCollections for the 13 cities\n",
    "city_collections = {\n",
    "    'Melbourne': ee.FeatureCollection('projects/YOUR-GOOGLE-CLOUD-PROJECT-NAME/assets/urban_study_region/Melbourne'),\n",
    "    'LosAngeles': ee.FeatureCollection('projects/YOUR-GOOGLE-CLOUD-PROJECT-NAME/assets/urban_study_region/LosAngeles'),\n",
    "    'Helsinki': ee.FeatureCollection('projects/YOUR-GOOGLE-CLOUD-PROJECT-NAME/assets/urban_study_region/Helsinki'),\n",
    "    'MexicoCity': ee.FeatureCollection('projects/YOUR-GOOGLE-CLOUD-PROJECT-NAME/assets/urban_study_region/MexicoCity'),\n",
    "    'Austin': ee.FeatureCollection('projects/YOUR-GOOGLE-CLOUD-PROJECT-NAME/assets/urban_study_region/Austin'),\n",
    "    'Minneapolis': ee.FeatureCollection('projects/YOUR-GOOGLE-CLOUD-PROJECT-NAME/assets/urban_study_region/Minneapolis'),\n",
    "    'Munich': ee.FeatureCollection('projects/YOUR-GOOGLE-CLOUD-PROJECT-NAME/assets/urban_study_region/Munich'),\n",
    "    'Turin': ee.FeatureCollection('projects/YOUR-GOOGLE-CLOUD-PROJECT-NAME/assets/urban_study_region/Turin'),\n",
    "    'PortoAlegre': ee.FeatureCollection('projects/YOUR-GOOGLE-CLOUD-PROJECT-NAME/assets/urban_study_region/PortoAlegre'),\n",
    "    'Valencia': ee.FeatureCollection('projects/YOUR-GOOGLE-CLOUD-PROJECT-NAME/assets/urban_study_region/Valencia'),\n",
    "    'Belfast': ee.FeatureCollection('projects/YOUR-GOOGLE-CLOUD-PROJECT-NAME/assets/urban_study_region/Belfast'),\n",
    "    'Chennai': ee.FeatureCollection('projects/YOUR-GOOGLE-CLOUD-PROJECT-NAME/assets/urban_study_region/Chennai'),\n",
    "    'Vic': ee.FeatureCollection('projects/YOUR-GOOGLE-CLOUD-PROJECT-NAME/assets/urban_study_region/Vic'),\n",
    "}\n",
    "\n",
    "# Add the 'geo_type' property to each feature\n",
    "def add_geo_type(feature):\n",
    "    return feature.set('geo_type', feature.geometry().type())\n",
    "\n",
    "# Map the function over each individual FeatureCollection in the dictionary\n",
    "mapped_collections = {city: city_collection.map(add_geo_type) for city, city_collection in city_collections.items()}\n",
    "\n",
    "# Type in your city here\n",
    "city = mapped_collections.get(city_var)\n",
    "aos_public_osm = ee.FeatureCollection('projects/YOUR-GOOGLE-CLOUD-PROJECT-NAME/assets/aos_public_osm/' + f'{city_var}_aos_public_osm')\n",
    "\n",
    "# Filter for area greater than or equal to 1 ha\n",
    "aos_public_osm_filtered_1ha = aos_public_osm.filter(ee.Filter.gte('aos_ha_pub', 1))\n",
    "\n",
    "# Define analysis dates as the year from March 1st 2023 to March 1st 2024\n",
    "start_date = '2023-03-01';\n",
    "end_date = '2024-03-01';\n",
    "\n",
    "# Define map\n",
    "Map = geemap.Map()\n",
    "\n",
    "# Get the geometry and bounding box\n",
    "geometry = city.geometry();\n",
    "bounding_box = geometry.bounds();\n",
    "\n",
    "# Define visualisation\n",
    "black_outline_vis = {\n",
    "    'color': 'Black',\n",
    "    'width': 2,\n",
    "}\n",
    "\n",
    "purple_outline_vis = {\n",
    "    'color': 'Purple',\n",
    "    'width': 2,\n",
    "}\n",
    "\n",
    "# Add layers to map\n",
    "Map.addLayer(city, black_outline_vis, 'Urban Study Region')\n",
    "Map.addLayer(aos_public_osm_filtered_1ha, purple_outline_vis, 'AOS Public 1ha OSM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c591eba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LANDSAT 8 IMAGERY CLOUD MASK\n",
    "\n",
    "# Function to mask clouds from Landsat 8 Collection 2, Level 2 using the QA_PIXEL band (CFMask).\n",
    "def maskl8clouds(image):\n",
    "    qa_mask = image.select('QA_PIXEL').bitwiseAnd(int('11111', 2)).eq(0)\n",
    "    saturation_mask = image.select('QA_RADSAT').eq(0)\n",
    "\n",
    "    optical_bands = image.select('SR_B.*').multiply(0.0000275).add(-0.2)\n",
    "    thermal_bands = image.select('ST_B.*').multiply(0.00341802).add(149.0)\n",
    "\n",
    "    return image.addBands(optical_bands, None, True) \\\n",
    "        .addBands(thermal_bands, None, True) \\\n",
    "        .updateMask(qa_mask) \\\n",
    "        .updateMask(saturation_mask)\n",
    "\n",
    "# Map the function over one year of data\n",
    "landsat_collection = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2') \\\n",
    "    .filterDate(start_date, end_date) \\\n",
    "    .map(maskl8clouds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46152527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENTINEL MASK CLOUDS AND NDVI FUNCTION\n",
    "\n",
    "# Function to mask clouds from Sentinel 2 imagery using the QA band\n",
    "def mask_s2_clouds(image):\n",
    "    qa = image.select('QA60')\n",
    "    \n",
    "    # Bits 10 and 11 are clouds and cirrus, respectively\n",
    "    cloud_bit_mask = 1 << 10\n",
    "    cirrus_bit_mask = 1 << 11\n",
    "    \n",
    "    # Both flags should be set to zero, indicating clear conditions\n",
    "    mask = qa.bitwiseAnd(cloud_bit_mask).eq(0).And(qa.bitwiseAnd(cirrus_bit_mask).eq(0))\n",
    "    \n",
    "    # Return the masked and scaled data, without the QA bands\n",
    "    return image.updateMask(mask).divide(10000).select([\"B.*\"]).copyProperties(image, [\"system:time_start\"])\n",
    "\n",
    "# Calculate NDVI\n",
    "def calculate_ndvi(image):\n",
    "    nir = image.select('B8')  # Near-infrared band\n",
    "    red = image.select('B4')  # Red band\n",
    "    ndvi = nir.subtract(red).divide(nir.add(red)).rename('NDVI')\n",
    "    return image.addBands(ndvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2899588c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NDVI CALCULATION - ANNUAL AVERAGE - SENTINEL\n",
    "\n",
    "# Load Sentinel-2 TOA reflectance data using dates defined earlier in this notebook\n",
    "sentinel_collection_annual_average = ee.ImageCollection('COPERNICUS/S2_HARMONIZED') \\\n",
    "    .filterBounds(bounding_box) \\\n",
    "    .filterDate(start_date, end_date) \\\n",
    "    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 90)) \\\n",
    "    .map(mask_s2_clouds)\n",
    "\n",
    "# Apply NDVI calculation to the image collection\n",
    "annual_average_ndvi_collection = sentinel_collection_annual_average.map(calculate_ndvi)\n",
    "\n",
    "# Calculate the overall average NDVI for all 12 months of the year\n",
    "annual_average_ndvi = annual_average_ndvi_collection.select('NDVI').mean()\n",
    "\n",
    "# Clip the NDVI image to the areas of open space to save processing time\n",
    "annual_average_ndvi_image_clipped = annual_average_ndvi.clip(aos_public_osm_filtered_1ha)\n",
    "\n",
    "# Clip the NDVI image to the city boundary\n",
    "annual_average_ndvi_image_clipped_city = annual_average_ndvi.clip(city)\n",
    "\n",
    "# Create a binary mask greater than or equal to NDVI 0.2\n",
    "binary_ndvi = annual_average_ndvi_image_clipped_city.gte(0.2).rename('Binary_NDVI');\n",
    "\n",
    "# Visualise the raster where white is NDVI greater than or equal to 0.2 and black is not\n",
    "binary_ndvi_vis = {\n",
    "    'min': 0,\n",
    "    'max': 1,\n",
    "    'palette': ['White','Black'],\n",
    "}\n",
    "\n",
    "# Define visualisation parameters for overall NDVI visualisation\n",
    "ndvi_vis = {\n",
    "    'min': -1,\n",
    "    'max': 1,\n",
    "    'palette': ['GhostWhite', 'PaleGreen', 'LightGreen', 'Green', 'ForestGreen']\n",
    "}\n",
    "\n",
    "# Add to map\n",
    "Map.addLayer(annual_average_ndvi_image_clipped, ndvi_vis, 'NDVI - Annual Average')\n",
    "Map.addLayer(binary_ndvi, binary_ndvi_vis, 'Binary NDVI');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d99eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE LARGE PUBLIC URBAN GREEN SPACE (LPUGS)\n",
    "\n",
    "# LPUGS defined as NDVI 0.2 - 1\n",
    "min_NDVI = 0.2\n",
    "max_NDVI = 1\n",
    "\n",
    "# Define mask based on max and min NDVI thresholds\n",
    "lpugs_areas_annual_average = annual_average_ndvi_image_clipped.gte(min_NDVI).And(annual_average_ndvi_image_clipped.lte(max_NDVI))\n",
    "\n",
    "# Apply mask\n",
    "lpugs_areas_annual_average_clip = lpugs_areas_annual_average.updateMask(\n",
    "    lpugs_areas_annual_average.gte(min_NDVI).And(lpugs_areas_annual_average.lte(max_NDVI))\n",
    ")\n",
    "\n",
    "# Define visualisation parameters and add to map\n",
    "lpugs_vis = {\n",
    "    'min': 0.2,\n",
    "    'max': 1,\n",
    "    'palette': ['Red'],\n",
    "}\n",
    "\n",
    "Map.addLayer(lpugs_areas_annual_average_clip, lpugs_vis, 'LPUGS - Annual Average NDVI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e707fe03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD NDVI ATTRIBUTES TO EACH AOS_PUBLIC_OSM\n",
    "\n",
    "def add_ndvi_to_feature(feature, image, name='NDVI'):\n",
    "    # Get the geometry of the feature\n",
    "    geometry = feature.geometry()\n",
    "\n",
    "    # Use reduceRegion to calculate the mean NDVI value within each polygon\n",
    "    ndvi_value = image.reduceRegion(\n",
    "        reducer=ee.Reducer.mean(),\n",
    "        geometry=geometry,\n",
    "        scale=10\n",
    "    ).get('NDVI')\n",
    "\n",
    "    # Set the calculated rounded NDVI as a property of the feature\n",
    "    return feature.set({name: ndvi_value})\n",
    "\n",
    "def calculate_ndvi_area(feature, image, name='LPUGS_area'):   \n",
    "    geometry = feature.geometry()\n",
    "    ndvi_area = image.multiply(ee.Image.pixelArea()).rename('Area')\n",
    "    ndvi_area_calc = ndvi_area.reduceRegion(\n",
    "        reducer=ee.Reducer.sum(),\n",
    "        geometry=geometry,\n",
    "        scale=10,\n",
    "        maxPixels=1e10\n",
    "    )\n",
    "    ndvi_area_m2 = ee.Number(ndvi_area_calc.get('Area'))\n",
    "    ndvi_area_ha = ndvi_area_m2.divide(1e4)\n",
    "    \n",
    "    # Set the calculated LPUGS area as a property of the feature\n",
    "    return feature.set({name: ndvi_area_ha})\n",
    "\n",
    "# Usage example\n",
    "attribute_name_ndvi_aa = 'NDVI_aa_av'\n",
    "attribute_name_lpugs_area_aa = 'LPUGS_aa_ha'\n",
    "\n",
    "with_annual_average_ndvi = aos_public_osm_filtered_1ha.map(lambda feature: add_ndvi_to_feature(feature, annual_average_ndvi_image_clipped, name=attribute_name_ndvi_aa))\n",
    "\n",
    "aos_public_osm_lpugs = with_annual_average_ndvi.map(lambda feature: calculate_ndvi_area(feature, lpugs_areas_annual_average_clip, name=attribute_name_lpugs_area_aa))\n",
    "\n",
    "# Filter for NDVI greater than or equal to 0.2\n",
    "aos_public_osm_lpugs_ndvi_0point2 = aos_public_osm_lpugs.filter(ee.Filter.gte('NDVI_aa_av', 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d634cd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILTER LAYER TO ONLY POLYGONS\n",
    "\n",
    "# Define a function to get the geometry type for a feature\n",
    "def get_geometry_type(feature):\n",
    "    # Create a dummy property 'geometryType' and set it to the geometry type\n",
    "    return feature.set('geometryType', ee.String(feature.geometry().type()))\n",
    "\n",
    "# Map the function over the FeatureCollection\n",
    "mapped_features = aos_public_osm_lpugs_ndvi_0point2.map(get_geometry_type)\n",
    "\n",
    "# Extract the 'geometryType' property as a list\n",
    "geometry_types_list = mapped_features.aggregate_array('geometryType')\n",
    "\n",
    "# Filter the features to exclude LineString on the server side\n",
    "filtered_features = mapped_features.filter(\n",
    "    ee.Filter.Or(\n",
    "        ee.Filter.eq('geometryType', 'Polygon'),\n",
    "        ee.Filter.eq('geometryType', 'MultiPolygon'),\n",
    "        ee.Filter.eq('geometryType', 'LinearRing')\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create a new FeatureCollection with only non-LineString features on the server side\n",
    "lpugs_final = ee.FeatureCollection(filtered_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ffbff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHOW MAP\n",
    "\n",
    "Map.centerObject(city);\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02766279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT LPUGS POLYGONS\n",
    "\n",
    "task = ee.batch.Export.table.toDrive(\n",
    "    collection=lpugs_final,\n",
    "    description='Export LPUGS Polygons to Drive ' + f'{city_var}',\n",
    "    fileNamePrefix='LPUGS_Polygons_' + f'{city_var}_2025',\n",
    "    fileFormat='SHP',\n",
    "    selectors=['fid', 'aos_id', 'aos_ha_pub', 'NDVI_aa_av', 'LPUGS_aa_ha']\n",
    ")\n",
    "task.start()\n",
    "\n",
    "# EXPORT NDVI RASTER\n",
    "\n",
    "task = ee.batch.Export.image.toDrive(\n",
    "    image=binary_ndvi,\n",
    "    description='Export NDVI Image to Drive ' + f'{city_var}',\n",
    "    fileNamePrefix='NDVI_0.2_' + f'{city_var}_2025',\n",
    "    fileFormat='GeoTIFF',\n",
    "    crs='EPSG:4326',\n",
    "    scale=10,\n",
    "    region=geometry,\n",
    "    maxPixels=1e13,\n",
    ")\n",
    "task.start()\n",
    "\n",
    "# Open your Google Drive to find the exported files ready for local download"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
